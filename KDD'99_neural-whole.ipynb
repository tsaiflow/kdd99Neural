{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports for this Notebook\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 494021 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "df = pd.read_csv(\"/Users/tsaiflow/Downloads/kddcup.data_10_percent_corrected\", header=None)\n",
    "df1 = pd.read_csv(\"/Users/tsaiflow/Downloads/kddcup.data.corrected\", header=None)\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "#print(\"Read {} rows.\".format(len(df1)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "df1.dropna(inplace=True,axis=1)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "\n",
    "df1.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display 5 rows\n",
    "#df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag-S3</th>\n",
       "      <th>flag-SF</th>\n",
       "      <th>flag-SH</th>\n",
       "      <th>land-0</th>\n",
       "      <th>land-1</th>\n",
       "      <th>logged_in-0</th>\n",
       "      <th>logged_in-1</th>\n",
       "      <th>is_host_login-0</th>\n",
       "      <th>is_guest_login-0</th>\n",
       "      <th>is_guest_login-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002879</td>\n",
       "      <td>0.138664</td>\n",
       "      <td>-0.04772</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.011578</td>\n",
       "      <td>-0.04772</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>-0.04772</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002840</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>-0.04772</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>-0.04772</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
       "0 -0.067792  -0.002879   0.138664        -0.04772 -0.002571 -0.044136   \n",
       "1 -0.067792  -0.002820  -0.011578        -0.04772 -0.002571 -0.044136   \n",
       "2 -0.067792  -0.002824   0.014179        -0.04772 -0.002571 -0.044136   \n",
       "3 -0.067792  -0.002840   0.014179        -0.04772 -0.002571 -0.044136   \n",
       "4 -0.067792  -0.002842   0.035214        -0.04772 -0.002571 -0.044136   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  \\\n",
       "0          -0.009782        -0.005679   -0.010552     -0.004676   \n",
       "1          -0.009782        -0.005679   -0.010552     -0.004676   \n",
       "2          -0.009782        -0.005679   -0.010552     -0.004676   \n",
       "3          -0.009782        -0.005679   -0.010552     -0.004676   \n",
       "4          -0.009782        -0.005679   -0.010552     -0.004676   \n",
       "\n",
       "         ...         flag-S3  flag-SF  flag-SH  land-0  land-1  logged_in-0  \\\n",
       "0        ...               0        1        0       1       0            0   \n",
       "1        ...               0        1        0       1       0            0   \n",
       "2        ...               0        1        0       1       0            0   \n",
       "3        ...               0        1        0       1       0            0   \n",
       "4        ...               0        1        0       1       0            0   \n",
       "\n",
       "   logged_in-1  is_host_login-0  is_guest_login-0  is_guest_login-1  \n",
       "0            1                1                 1                 0  \n",
       "1            1                1                 1                 0  \n",
       "2            1                1                 1                 0  \n",
       "3            1                1                 1                 0  \n",
       "4            1                1                 1                 0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "encode_text_dummy(df, 'is_host_login')\n",
    "encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "outcomes = encode_text_index(df, 'outcome')\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "df[0:5]\n",
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag-SF</th>\n",
       "      <th>flag-SH</th>\n",
       "      <th>land-0</th>\n",
       "      <th>land-1</th>\n",
       "      <th>logged_in-0</th>\n",
       "      <th>logged_in-1</th>\n",
       "      <th>is_host_login-0</th>\n",
       "      <th>is_host_login-1</th>\n",
       "      <th>is_guest_login-0</th>\n",
       "      <th>is_guest_login-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001777</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
       "0 -0.066833  -0.001720   0.068188       -0.015139 -0.001103 -0.026521   \n",
       "1 -0.066833  -0.001777   0.005325       -0.015139 -0.001103 -0.026521   \n",
       "2 -0.066833  -0.001698   0.000208       -0.015139 -0.001103 -0.026521   \n",
       "3 -0.066833  -0.001701   0.001455       -0.015139 -0.001103 -0.026521   \n",
       "4 -0.066833  -0.001695  -0.000942       -0.015139 -0.001103 -0.026521   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  \\\n",
       "0          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "1          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "2          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "3          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "4          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "\n",
       "         ...         flag-SF  flag-SH  land-0  land-1  logged_in-0  \\\n",
       "0        ...               1        0       1       0            0   \n",
       "1        ...               1        0       1       0            0   \n",
       "2        ...               1        0       1       0            0   \n",
       "3        ...               1        0       1       0            0   \n",
       "4        ...               1        0       1       0            0   \n",
       "\n",
       "   logged_in-1  is_host_login-0  is_host_login-1  is_guest_login-0  \\\n",
       "0            1                1                0                 1   \n",
       "1            1                1                0                 1   \n",
       "2            1                1                0                 1   \n",
       "3            1                1                0                 1   \n",
       "4            1                1                0                 1   \n",
       "\n",
       "   is_guest_login-1  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df1, 'duration')\n",
    "encode_text_dummy(df1, 'protocol_type')\n",
    "encode_text_dummy(df1, 'service')\n",
    "encode_text_dummy(df1, 'flag')\n",
    "encode_numeric_zscore(df1, 'src_bytes')\n",
    "encode_numeric_zscore(df1, 'dst_bytes')\n",
    "encode_text_dummy(df1, 'land')\n",
    "encode_numeric_zscore(df1, 'wrong_fragment')\n",
    "encode_numeric_zscore(df1, 'urgent')\n",
    "encode_numeric_zscore(df1, 'hot')\n",
    "encode_numeric_zscore(df1, 'num_failed_logins')\n",
    "encode_text_dummy(df1, 'logged_in')\n",
    "encode_numeric_zscore(df1, 'num_compromised')\n",
    "encode_numeric_zscore(df1, 'root_shell')\n",
    "encode_numeric_zscore(df1, 'su_attempted')\n",
    "encode_numeric_zscore(df1, 'num_root')\n",
    "encode_numeric_zscore(df1, 'num_file_creations')\n",
    "encode_numeric_zscore(df1, 'num_shells')\n",
    "encode_numeric_zscore(df1, 'num_access_files')\n",
    "encode_numeric_zscore(df1, 'num_outbound_cmds')\n",
    "encode_text_dummy(df1, 'is_host_login')\n",
    "encode_text_dummy(df1, 'is_guest_login')\n",
    "encode_numeric_zscore(df1, 'count')\n",
    "encode_numeric_zscore(df1, 'srv_count')\n",
    "encode_numeric_zscore(df1, 'serror_rate')\n",
    "encode_numeric_zscore(df1, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df1, 'rerror_rate')\n",
    "encode_numeric_zscore(df1, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df1, 'same_srv_rate')\n",
    "encode_numeric_zscore(df1, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df1, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_count')\n",
    "encode_numeric_zscore(df1, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df1, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df1, 'dst_host_srv_rerror_rate')\n",
    "outcomes = encode_text_index(df1, 'outcome')\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "df1.dropna(inplace=True,axis=1)\n",
    "df1[0:5]\n",
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag-S3</th>\n",
       "      <th>flag-SF</th>\n",
       "      <th>flag-SH</th>\n",
       "      <th>land-0</th>\n",
       "      <th>land-1</th>\n",
       "      <th>logged_in-0</th>\n",
       "      <th>logged_in-1</th>\n",
       "      <th>is_host_login-0</th>\n",
       "      <th>is_guest_login-0</th>\n",
       "      <th>is_guest_login-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001777</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.066833</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>-0.015139</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
       "0 -0.066833  -0.001720   0.068188       -0.015139 -0.001103 -0.026521   \n",
       "1 -0.066833  -0.001777   0.005325       -0.015139 -0.001103 -0.026521   \n",
       "2 -0.066833  -0.001698   0.000208       -0.015139 -0.001103 -0.026521   \n",
       "3 -0.066833  -0.001701   0.001455       -0.015139 -0.001103 -0.026521   \n",
       "4 -0.066833  -0.001695  -0.000942       -0.015139 -0.001103 -0.026521   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  \\\n",
       "0          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "1          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "2          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "3          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "4          -0.004391        -0.002097   -0.008258     -0.004546   \n",
       "\n",
       "         ...         flag-S3  flag-SF  flag-SH  land-0  land-1  logged_in-0  \\\n",
       "0        ...               0        1        0       1       0            0   \n",
       "1        ...               0        1        0       1       0            0   \n",
       "2        ...               0        1        0       1       0            0   \n",
       "3        ...               0        1        0       1       0            0   \n",
       "4        ...               0        1        0       1       0            0   \n",
       "\n",
       "   logged_in-1  is_host_login-0  is_guest_login-0  is_guest_login-1  \n",
       "0            1                1                 1                 0  \n",
       "1            1                1                 1                 0  \n",
       "2            1                1                 1                 0  \n",
       "3            1                1                 1                 0  \n",
       "4            1                1                 1                 0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df1['service-aol']\n",
    "del df1['service-harvest']\n",
    "del df1['service-http_2784']\n",
    "del df1['service-http_8001']\n",
    "del df1['is_host_login-1']\n",
    "df1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df_trial = df[0:5]\n",
    "df1_trial = df1[0:5]\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df_trial.to_excel(writer, sheet_name='Sheet1')\n",
    "df1_trial.to_excel(writer, sheet_name='Sheet2')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# writer = pd.ExcelWriter('pandas_simple1.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# # Convert the dataframe to an XlsxWriter Excel object.\n",
    "# df1.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break into X (predictors) & y (prediction)\n",
    "#x, y = to_xy(df,'outcome')\n",
    "x_train, y_train = to_xy(df,'outcome')\n",
    "x_test, y_test = to_xy(df1,'outcome')\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494021, 120)\n",
      "(4898431, 120)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create neural net\n",
    "model = Sequential()\n",
    "\n",
    "# Used relu for activation function\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# output layer\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                1210      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 23)                46        \n",
      "=================================================================\n",
      "Total params: 2,327\n",
      "Trainable params: 2,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # TODO:  Create two empty lists, self.loss and self.val_acc\n",
    "        self.losses = []\n",
    "        self.accs = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        # TODO:  This is called at the end of each batch.  \n",
    "        # Add the loss in logs.get('loss') to the loss list\n",
    "        loss = logs.get('loss')\n",
    "        acc = logs.get('acc')\n",
    "        self.losses.append(loss)\n",
    "        self.accs.append(acc)\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # TODO:  This is called at the end of each epoch.  \n",
    "        # Add the test accuracy in logs.get('loss') to the val_acc list\n",
    "        acc = logs.get('val_acc')\n",
    "        val_loss = logs.get('val_loss')\n",
    "        self.val_acc.append(acc)\n",
    "        self.val_loss.append(val_loss)\n",
    "\n",
    "# Create an instance of the history callback\n",
    "history_cb = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# optimizer defined\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#opt = optimizers.Adam(lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## compile\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 494021 samples, validate on 4898431 samples\n",
      "Epoch 1/10\n",
      "63s - loss: 0.3170 - acc: 0.9020 - val_loss: 0.0691 - val_acc: 0.9891\n",
      "Epoch 2/10\n",
      "80s - loss: 0.0662 - acc: 0.9867 - val_loss: 0.0285 - val_acc: 0.9931\n",
      "Epoch 3/10\n",
      "62s - loss: 0.0479 - acc: 0.9895 - val_loss: 0.0211 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "146s - loss: 0.0414 - acc: 0.9918 - val_loss: 0.0201 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "65s - loss: 0.0395 - acc: 0.9925 - val_loss: 0.0183 - val_acc: 0.9979\n",
      "Epoch 6/10\n",
      "60s - loss: 0.0367 - acc: 0.9936 - val_loss: 0.0163 - val_acc: 0.9979\n",
      "Epoch 7/10\n",
      "63s - loss: 0.0346 - acc: 0.9941 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 8/10\n",
      "60s - loss: 0.0340 - acc: 0.9947 - val_loss: 0.0188 - val_acc: 0.9973\n",
      "Epoch 9/10\n",
      "59s - loss: 0.0333 - acc: 0.9951 - val_loss: 0.0192 - val_acc: 0.9981\n",
      "Epoch 10/10\n",
      "59s - loss: 0.0315 - acc: 0.9953 - val_loss: 0.0172 - val_acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d2ad748>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "batch_size = 100\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[history_cb],verbose=2,epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-21253b29b09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from sklearn.metrics import confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from sklearn.metrics import confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# C = confusion_matrix(xts,yhat_ts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Normalize the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# np.shape(x_test_pred)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# C = confusion_matrix(xts,yhat_ts)\n",
    "# # Normalize the confusion matrix\n",
    "# Csum = np.sum(C,1)\n",
    "# C = C / Csum[None,:]\n",
    "# # Print the confusion matrix\n",
    "# print(np.array_str(C, precision=3, suppress_small=True)) \n",
    "# plt.imshow(C, interpolation='none')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEYCAYAAADmugmLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e666198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valAcc = history_cb.val_acc\n",
    "valLoss = history_cb.val_loss\n",
    "epoch_it = np.arange(1,11)\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_it, valAcc)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_it, valLoss)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = history_cb.losses\n",
    "ntr = np.shape(x_train)[0]\n",
    "epochNum = []\n",
    "for i in range(49410):\n",
    "    epochNum.append(i*batch_size/ntr)\n",
    "matplotlib.pyplot.semilogy(epochNum, Ls)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates = [0.01,0.001,0.0001]\n",
    "batch_size = 100\n",
    "loss_hist = []\n",
    "val_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# output layer\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=rates[0], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "## compile\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_cb0 = LossHistory()\n",
    "\n",
    "batch_size = 100\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[history_cb0],verbose=2,epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# output layer\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=rates[1], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "## compile\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_cb1 = LossHistory()\n",
    "\n",
    "batch_size = 100\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[history_cb1],verbose=2,epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# output layer\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=rates[2], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "## compile\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_cb2 = LossHistory()\n",
    "\n",
    "batch_size = 100\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[history_cb2],verbose=2,epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valAcc0 = history_cb0.val_acc\n",
    "valAcc1 = history_cb1.val_acc\n",
    "valAcc2 = history_cb2.val_acc\n",
    "epoch_it = np.arange(1,11)\n",
    "plt.plot(epoch_it, valAcc0)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.legend(['rates = 0.01'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_it, valAcc1)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.legend(['rates = 0.001'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_it, valAcc2)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.legend(['rates = 0.0001'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "Ls2 = history_cb2.losses\n",
    "Ls0 = history_cb0.losses\n",
    "Ls1 = history_cb1.losses\n",
    "\n",
    "ntr = np.shape(x_train)[0]\n",
    "epochNum = []\n",
    "for i in range(37060):\n",
    "    epochNum.append(i*batch_size/ntr)\n",
    "\n",
    "matplotlib.pyplot.semilogy(epochNum, Ls0, epochNum, Ls1, epochNum, Ls2)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['rates = 0.01','rates = 0.001','rates = 0.0001'])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.semilogy(epochNum, Ls0)\n",
    "#matplotlib.pyplot.semilogy(epochNum, Ls1)\n",
    "#matplotlib.pyplot.semilogy(epochNum, Ls2)\n",
    "plt.legend(['rates = 0.01','rates = 0.001','rates = 0.0001'])\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
